----------------------------------------------------------------
   Matrix Factorization Feed-forward Neural Network -> MLP   
----------------------------------------------------------------
Persentase data latih: 89.84%
Persentase data uji  : 10.16%


Hyperparameter Matrix Factorization:
Latent factors / Dimensi laten: 42
Learning rate                 : 0.05
Regularization parameter      : 0.02
Jumlah epoch / training       : 88


Epoch 1/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 58ms/step - loss: 12.3457 - val_loss: 11.7434
Epoch 2/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 12.2155 - val_loss: 11.4246
Epoch 3/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 11.3899 - val_loss: 11.0388
Epoch 4/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 11.2619 - val_loss: 10.5362
Epoch 5/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 10.2622 - val_loss: 9.8692
Epoch 6/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 9.5877 - val_loss: 8.9634
Epoch 7/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 8.8037 - val_loss: 7.7477
Epoch 8/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 7.0057 - val_loss: 6.1702
Epoch 9/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 11ms/step - loss: 5.0816 - val_loss: 4.4327
Epoch 10/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 3.2108 - val_loss: 3.5190
Epoch 11/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 11ms/step - loss: 3.1477 - val_loss: 3.5383
Epoch 12/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 11ms/step - loss: 3.3414 - val_loss: 3.0461
Epoch 13/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 2.5864 - val_loss: 2.7620
Epoch 14/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 1.9980 - val_loss: 2.7539
Epoch 15/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 1.9350 - val_loss: 2.6707
Epoch 16/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.9284 - val_loss: 2.4688
Epoch 17/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.6519 - val_loss: 2.2993
Epoch 18/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.5172 - val_loss: 2.2670
Epoch 19/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.4530 - val_loss: 2.2602
Epoch 20/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.4380 - val_loss: 2.1888
Epoch 21/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.3948 - val_loss: 2.1161
Epoch 22/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.3039 - val_loss: 2.0799
Epoch 23/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.2922 - val_loss: 2.0580
Epoch 24/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.1566 - val_loss: 2.0374
Epoch 25/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.1813 - val_loss: 2.0274
Epoch 26/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.0973 - val_loss: 2.0365
Epoch 27/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.0138 - val_loss: 2.0271
Epoch 28/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.0320 - val_loss: 2.0043
Epoch 29/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 1.0018 - val_loss: 1.9872
Epoch 30/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.9147 - val_loss: 1.9803
Epoch 31/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.9196 - val_loss: 1.9735
Epoch 32/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.8714 - val_loss: 1.9767
Epoch 33/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.8682 - val_loss: 1.9697
Epoch 34/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.8280 - val_loss: 1.9584
Epoch 35/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.7792 - val_loss: 1.9387
Epoch 36/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.7455 - val_loss: 1.9141
Epoch 37/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.7006 - val_loss: 1.9092
Epoch 38/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.7092 - val_loss: 1.9130
Epoch 39/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.6848 - val_loss: 1.9138
Epoch 40/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.7156 - val_loss: 1.8873
Epoch 41/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 11ms/step - loss: 0.6445 - val_loss: 1.8713
Epoch 42/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.6057 - val_loss: 1.8664
Epoch 43/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.6348 - val_loss: 1.8587
Epoch 44/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 11ms/step - loss: 0.5856 - val_loss: 1.8447
Epoch 45/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.5922 - val_loss: 1.8393
Epoch 46/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.5364 - val_loss: 1.8272
Epoch 47/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.5133 - val_loss: 1.8273
Epoch 48/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.5130 - val_loss: 1.8235
Epoch 49/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.4919 - val_loss: 1.8070
Epoch 50/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.5293 - val_loss: 1.7860
Epoch 51/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.4394 - val_loss: 1.7856
Epoch 52/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.4405 - val_loss: 1.7902
Epoch 53/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.4526 - val_loss: 1.7832
Epoch 54/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.4274 - val_loss: 1.7699
Epoch 55/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.3837 - val_loss: 1.7572
Epoch 56/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.4076 - val_loss: 1.7403
Epoch 57/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.3766 - val_loss: 1.7307
Epoch 58/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - loss: 0.3649 - val_loss: 1.7191
Epoch 59/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.3427 - val_loss: 1.6967
Epoch 60/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.3415 - val_loss: 1.6828
Epoch 61/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.2970 - val_loss: 1.6688
Epoch 62/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.2945 - val_loss: 1.6680
Epoch 63/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.2858 - val_loss: 1.6509
Epoch 64/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.2798 - val_loss: 1.6353
Epoch 65/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.2540 - val_loss: 1.6164
Epoch 66/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - loss: 0.2576 - val_loss: 1.6039
Epoch 67/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - loss: 0.2425 - val_loss: 1.5837
Epoch 68/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.2314 - val_loss: 1.5728
Epoch 69/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - loss: 0.2334 - val_loss: 1.5636
Epoch 70/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.2185 - val_loss: 1.5543
Epoch 71/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.2075 - val_loss: 1.5427
Epoch 72/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.1960 - val_loss: 1.5262
Epoch 73/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.1798 - val_loss: 1.5195
Epoch 74/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 11ms/step - loss: 0.1743 - val_loss: 1.5197
Epoch 75/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.1685 - val_loss: 1.5088
Epoch 76/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - loss: 0.1572 - val_loss: 1.4971
Epoch 77/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.1437 - val_loss: 1.4937
Epoch 78/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.1575 - val_loss: 1.4906
Epoch 79/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.1393 - val_loss: 1.4880
Epoch 80/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - loss: 0.1399 - val_loss: 1.4808
Epoch 81/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.1328 - val_loss: 1.4762
Epoch 82/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - loss: 0.1171 - val_loss: 1.4684
Epoch 83/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.1206 - val_loss: 1.4632
Epoch 84/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.1135 - val_loss: 1.4629
Epoch 85/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.0972 - val_loss: 1.4628
Epoch 86/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 12ms/step - loss: 0.1021 - val_loss: 1.4610
Epoch 87/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.1111 - val_loss: 1.4593
Epoch 88/88
3/3 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - loss: 0.1100 - val_loss: 1.4547
6709/6709 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 713us/step 

ğŸ“Š Evaluasi Model MLP (MF + feature + Swish):
MAE : 0.3291
MSE : 0.3300
RMSE: 0.5744

Total kombinasi user-item diuji : 214671
Diproses oleh model            : 214671
Memiliki rating aktual         : 453
        userId  itemId  actual_rating  ffnn_predicted_rating
0           15   80225            0.0                    1.0
1           15   78657            0.0                    1.0
2           15   77673            0.0                    1.0
3           15   74454            0.0                    1.0
4           15   76677            0.0                    1.0
...        ...     ...            ...                    ...
214666    8562   79713            0.0                    2.0
214667    8562   83015            0.0                    2.0
214668    8562   79554            0.0                    2.0
214669    8562   79464            0.0                    4.0
214670    8562   76836            0.0                    3.0

[214671 rows x 4 columns]

ğŸ“ Hasil prediksi disimpan ke: b_ffnn_ratings.csv
â±ï¸ Waktu yang dibutuhkan: 162.63 detik