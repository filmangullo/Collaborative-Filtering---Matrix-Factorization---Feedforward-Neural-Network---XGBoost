||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
                              MATRIX FACTORIZATION
                                      and
           FEEDFORWARD NEURAL NETWORK BASED ON MULTI-LAYER PERCEPTRON
||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
--------------------------------------------------------------------------------
                                   LOAD DATA
--------------------------------------------------------------------------------
Total Item: 9742
Total Rating  : 100836
--------------------------------------------------------------------------------
                                 DATA SPLITTING
--------------------------------------------------------------------------------
Persentase data latih: 90.00%
Persentase data uji  : 10.00%


--------------------------------------------------------------------------------
                                DATA PREPARATION
--------------------------------------------------------------------------------
========== ONE-HOT ENCODED FEATURES ==========
          id  (no genres listed)  Action  Adventure  Animation  ...  Romance  Sci-Fi  Thriller  War  Western
0          1                   0       0          1          1  ...        0       0         0    0        0
1          2                   0       0          1          0  ...        0       0         0    0        0
2          3                   0       0          0          0  ...        1       0         0    0        0
3          4                   0       0          0          0  ...        1       0         0    0        0
4          5                   0       0          0          0  ...        0       0         0    0        0
...      ...                 ...     ...        ...        ...  ...      ...     ...       ...  ...      ...
9737  193581                   0       1          0          1  ...        0       0         0    0        0
9738  193583                   0       0          0          1  ...        0       0         0    0        0
9739  193585                   0       0          0          0  ...        0       0         0    0        0
9740  193587                   0       1          0          1  ...        0       0         0    0        0
9741  193609                   0       0          0          0  ...        0       0         0    0        0

[9742 rows x 21 columns]

Dimensi data akhir (item + fitur): (9742, 21)


========== USER-ITEM RATING MATRIX (PIVOT TABLE)  ==========
itemId  1       2       3       4       5       6       7       ...  193573  193579  193581  193583  193585  193587  193609
userId                                                          ...                                                     
1          4.0     NaN     4.0     NaN     NaN     4.0     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
2          NaN     NaN     NaN     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
3          NaN     NaN     NaN     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
4          NaN     NaN     NaN     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
5          NaN     NaN     NaN     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
...        ...     ...     ...     ...     ...     ...     ...  ...     ...     ...     ...     ...     ...     ...     ...
606        2.5     NaN     NaN     NaN     NaN     NaN     2.5  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
607        4.0     NaN     NaN     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
608        2.5     2.0     2.0     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
609        3.0     NaN     NaN     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN
610        5.0     NaN     NaN     NaN     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN

[610 rows x 9742 columns]


Hyperparameter Matrix Factorization:
Latent factors / Dimensi laten: 64
Learning rate                 : 0.002
Regularization parameter      : 0.05
Jumlah epoch / training       : 40


Hyperparameter MLP:
Struktur Hidden Layer     : [128, 64, 32, 16]
Learning Rate             : 0.005
Batch Size                : 64
Jumlah epoch / training   : 55
Early Stopping (Patience) : 15


Epoch 1/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 1ms/step - loss: 1.0196 - val_loss: 0.8574
Epoch 2/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.6966 - val_loss: 0.7229
Epoch 3/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 1ms/step - loss: 0.6766 - val_loss: 0.6772
Epoch 4/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 1ms/step - loss: 0.6430 - val_loss: 0.6685
Epoch 5/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 991us/step - loss: 0.6442 - val_loss: 0.6459
Epoch 6/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 985us/step - loss: 0.6260 - val_loss: 0.6486
Epoch 7/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 989us/step - loss: 0.6209 - val_loss: 0.6438
Epoch 8/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 977us/step - loss: 0.6147 - val_loss: 0.6329
Epoch 9/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 958us/step - loss: 0.6085 - val_loss: 0.6291
Epoch 10/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.6105 - val_loss: 0.7109
Epoch 11/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 989us/step - loss: 0.5933 - val_loss: 0.6533
Epoch 12/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 991us/step - loss: 0.5944 - val_loss: 0.6281
Epoch 13/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 981us/step - loss: 0.5859 - val_loss: 0.6217
Epoch 14/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 955us/step - loss: 0.5885 - val_loss: 0.6060
Epoch 15/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5728 - val_loss: 0.7504
Epoch 16/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 965us/step - loss: 0.6124 - val_loss: 0.6093
Epoch 17/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 995us/step - loss: 0.5801 - val_loss: 0.6073
Epoch 18/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 986us/step - loss: 0.5780 - val_loss: 0.5955
Epoch 19/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5718 - val_loss: 0.6170
Epoch 20/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5791 - val_loss: 0.6030
Epoch 21/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 1ms/step - loss: 0.6602 - val_loss: 0.6145
Epoch 22/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 1ms/step - loss: 0.5764 - val_loss: 0.6039
Epoch 23/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5731 - val_loss: 0.6051
Epoch 24/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 992us/step - loss: 0.5711 - val_loss: 0.6058
Epoch 25/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 962us/step - loss: 0.5597 - val_loss: 0.5996
Epoch 26/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5630 - val_loss: 0.6098
Epoch 27/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 963us/step - loss: 0.5479 - val_loss: 0.5860
Epoch 28/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 976us/step - loss: 0.5428 - val_loss: 0.5999
Epoch 29/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 977us/step - loss: 0.5495 - val_loss: 0.6248
Epoch 30/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5469 - val_loss: 0.6047
Epoch 31/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5402 - val_loss: 0.5998
Epoch 32/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 985us/step - loss: 0.5448 - val_loss: 0.5935
Epoch 33/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 978us/step - loss: 0.5309 - val_loss: 0.5970
Epoch 34/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 978us/step - loss: 0.5244 - val_loss: 0.5798
Epoch 35/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 997us/step - loss: 0.5290 - val_loss: 0.5877
Epoch 36/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 954us/step - loss: 0.5306 - val_loss: 0.5868
Epoch 37/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 990us/step - loss: 0.5269 - val_loss: 0.6829
Epoch 38/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 948us/step - loss: 0.5458 - val_loss: 0.5694
Epoch 39/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5213 - val_loss: 0.5700
Epoch 40/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - loss: 0.5235 - val_loss: 0.5986
Epoch 41/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 972us/step - loss: 0.5200 - val_loss: 0.6092
Epoch 42/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 988us/step - loss: 0.5262 - val_loss: 0.5775
Epoch 43/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 956us/step - loss: 0.5117 - val_loss: 0.5736
Epoch 44/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 971us/step - loss: 0.5128 - val_loss: 0.5871
Epoch 45/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 955us/step - loss: 0.5092 - val_loss: 0.5739
Epoch 46/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 973us/step - loss: 0.5089 - val_loss: 0.5793
Epoch 47/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 964us/step - loss: 0.5117 - val_loss: 0.5703
Epoch 48/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 979us/step - loss: 0.5044 - val_loss: 0.5886
Epoch 49/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 974us/step - loss: 0.5089 - val_loss: 0.5807
Epoch 50/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 959us/step - loss: 0.5057 - val_loss: 0.5662
Epoch 51/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 971us/step - loss: 0.5050 - val_loss: 0.5940
Epoch 52/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 965us/step - loss: 0.5057 - val_loss: 0.5705
Epoch 53/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 985us/step - loss: 0.5085 - val_loss: 0.6004
Epoch 54/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 964us/step - loss: 0.5116 - val_loss: 0.5757
Epoch 55/55
1206/1206 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 987us/step - loss: 0.5039 - val_loss: 0.5825

ğŸ“Š Evaluasi Model MLP (MF + feature + Swish):
MAE : 0.5634
MSE : 0.5700
RMSE: 0.7550

Total kombinasi user-item diuji : 5942620
Diproses oleh model            : 5942620
Memiliki rating aktual         : 100836
         userId  itemId  actual_rating  ffnn_predicted_rating
0             1       1            4.0                    4.0
1             1       2            0.0                    4.0
2             1       3            4.0                    4.0
3             1       4            0.0                    3.0
4             1       5            0.0                    4.0
...         ...     ...            ...                    ...
5942615     610  193581            0.0                    3.0
5942616     610  193583            0.0                    3.0
5942617     610  193585            0.0                    3.0
5942618     610  193587            0.0                    3.0
5942619     610  193609            0.0                    3.0

[5942620 rows x 4 columns]

ğŸ“ Hasil prediksi disimpan ke: dataset_movielens/b_ffnn_ratings.csv
â±ï¸ Waktu yang dibutuhkan: 4623.97 detik