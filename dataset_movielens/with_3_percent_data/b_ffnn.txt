----------------------------------------------------------------
   Matrix Factorization Feed-forward Neural Network -> MLP
----------------------------------------------------------------
Persentase data latih: 89.98%
Persentase data uji  : 10.02%


Hyperparameter Matrix Factorization:
Latent factors / Dimensi laten: 42
Learning rate                 : 0.005
Regularization parameter      : 0.05
Jumlah epoch / training       : 50


Epoch 1/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 1s 20ms/step - loss: 12.3884 - val_loss: 8.9104
Epoch 2/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 8.0741 - val_loss: 4.6241
Epoch 3/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 4.0067 - val_loss: 2.2269
Epoch 4/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 2.5214 - val_loss: 2.2423
Epoch 5/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 2.0279 - val_loss: 1.8155
Epoch 6/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.7107 - val_loss: 1.7097
Epoch 7/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.5854 - val_loss: 1.5720
Epoch 8/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.4445 - val_loss: 1.5028
Epoch 9/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.3924 - val_loss: 1.4218
Epoch 10/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.3396 - val_loss: 1.3584
Epoch 11/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.2506 - val_loss: 1.3227
Epoch 12/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.3124 - val_loss: 1.2869
Epoch 13/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.2176 - val_loss: 1.2492
Epoch 14/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.2160 - val_loss: 1.2077
Epoch 15/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.1435 - val_loss: 1.1791
Epoch 16/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.1060 - val_loss: 1.1527
Epoch 17/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.0746 - val_loss: 1.1256
Epoch 18/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.0852 - val_loss: 1.1048
Epoch 19/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.0627 - val_loss: 1.0863
Epoch 20/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.0194 - val_loss: 1.0695
Epoch 21/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 1.0113 - val_loss: 1.0563
Epoch 22/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9931 - val_loss: 1.0449
Epoch 23/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9651 - val_loss: 1.0349
Epoch 24/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9495 - val_loss: 1.0299
Epoch 25/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9599 - val_loss: 1.0202
Epoch 26/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9237 - val_loss: 1.0168
Epoch 27/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9392 - val_loss: 1.0113
Epoch 28/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9350 - val_loss: 1.0099
Epoch 29/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9280 - val_loss: 1.0102
Epoch 30/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9711 - val_loss: 1.0042
Epoch 31/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8938 - val_loss: 0.9985
Epoch 32/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9001 - val_loss: 0.9992
Epoch 33/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8884 - val_loss: 0.9987
Epoch 34/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9148 - val_loss: 0.9948
Epoch 35/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9127 - val_loss: 0.9952
Epoch 36/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8895 - val_loss: 0.9895
Epoch 37/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.8633 - val_loss: 0.9904
Epoch 38/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9133 - val_loss: 0.9946
Epoch 39/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9137 - val_loss: 0.9872
Epoch 40/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9080 - val_loss: 0.9917
Epoch 41/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8691 - val_loss: 0.9820
Epoch 42/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8802 - val_loss: 0.9840
Epoch 43/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8737 - val_loss: 0.9867
Epoch 44/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.9188 - val_loss: 0.9784
Epoch 45/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.8691 - val_loss: 0.9807
Epoch 46/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8837 - val_loss: 0.9784
Epoch 47/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8492 - val_loss: 0.9743
Epoch 48/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8937 - val_loss: 0.9751
Epoch 49/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8942 - val_loss: 0.9769
Epoch 50/50
8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.8674 - val_loss: 0.9736
4240/4240 ━━━━━━━━━━━━━━━━━━━━ 2s 427us/step

📊 Evaluasi Model MLP (MF + feature + Swish):
MAE : 0.7352
MSE : 0.9046
RMSE: 0.9511

Total kombinasi user-item diuji : 135659
Diproses oleh model            : 135659
Memiliki rating aktual         : 3044
        userId  itemId  actual_rating  ffnn_predicted_rating
0            1   72489            0.0                    3.5
1            1  114265            0.0                    2.6
2            1    6615            0.0                    3.0
3            1    7092            0.0                    3.1
4            1   93723            0.0                    2.7
...        ...     ...            ...                    ...
135654     610    6163            0.0                    3.0
135655     610    1762            0.0                    2.8
135656     610    7993            0.0                    3.1
135657     610   43928            2.0                    2.9
135658     610    6385            0.0                    3.6

[135659 rows x 4 columns]

📁 Hasil prediksi disimpan ke: b_ffnn_ratings.csv
⏱️ Waktu yang dibutuhkan: 167.46 detik